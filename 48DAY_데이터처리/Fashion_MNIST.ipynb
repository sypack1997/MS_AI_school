{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "1. \n",
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model done\n",
      "set vars and device done\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.372018\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.469477\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.634011\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.411023\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.327723\n",
      "\n",
      "Test set: Average loss: 0.4722, Accuracy: 8277/10000 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.347718\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.237241\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.552695\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.439620\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.360786\n",
      "\n",
      "Test set: Average loss: 0.4206, Accuracy: 8409/10000 (84%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.394550\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.462735\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.296683\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.210451\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.268203\n",
      "\n",
      "Test set: Average loss: 0.3831, Accuracy: 8601/10000 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.323166\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.285978\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.231975\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.370068\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.294726\n",
      "\n",
      "Test set: Average loss: 0.3848, Accuracy: 8631/10000 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.343959\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.374610\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.113591\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.236434\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.397305\n",
      "\n",
      "Test set: Average loss: 0.3642, Accuracy: 8715/10000 (87%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.333236\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.216225\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.344892\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.278535\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.197710\n",
      "\n",
      "Test set: Average loss: 0.3589, Accuracy: 8694/10000 (87%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.339036\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.272004\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.262950\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.295259\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.285503\n",
      "\n",
      "Test set: Average loss: 0.3535, Accuracy: 8729/10000 (87%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.162411\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.384676\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.231428\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.468150\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.143009\n",
      "\n",
      "Test set: Average loss: 0.3716, Accuracy: 8684/10000 (87%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.167888\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.167344\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.203038\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.268923\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.337557\n",
      "\n",
      "Test set: Average loss: 0.3450, Accuracy: 8778/10000 (88%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.221924\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.394346\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.339571\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.314447\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.390051\n",
      "\n",
      "Test set: Average loss: 0.3629, Accuracy: 8719/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "4. \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'], skiprows=[0])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        try:\n",
    "            image = read_image(img_path)\n",
    "        except:\n",
    "            print(self.img_labels.iloc[idx, 0])\n",
    "            exit()\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define Neural Networks Model.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h1 = F.relu(self.fc1(x.view(-1, 784)))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        h3 = F.relu(self.fc3(h2))\n",
    "        h4 = F.relu(self.fc4(h3))\n",
    "        h5 = F.relu(self.fc5(h4))\n",
    "        h6 = self.fc6(h5)\n",
    "        return F.log_softmax(h6, dim=1)\n",
    "\n",
    "#Prepare Data Loader for Training and Validation\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "print(\"init model done\")\n",
    "\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "no_cuda = True\n",
    "seed = 1\n",
    "log_interval = 200\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "print(\"set vars and device done\")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "train_dataset = CustomImageDataset(\n",
    "    annotations_file='./test_folder/FashionMNIST/train_annotations.csv',\n",
    "    img_dir='./test_folder/FashionMNIST/train_iamges/',\n",
    "    )\n",
    "\n",
    "test_dataset = CustomImageDataset(\n",
    "    annotations_file='./test_folder/FashionMNIST/test_annotations.csv',\n",
    "    img_dir='./test_folder/FashionMNIST/test_iamges/',\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size = test_batch_size, shuffle = True, **kwargs)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(log_interval, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format\n",
    "          (test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train(log_interval, model, device, train_loader, optimizer, epoch)\n",
    "    test(log_interval, model, device, test_loader)\n",
    "torch.save(model, './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "# daya_FashionMNIST_test, train ubyte download\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "     root = \"data\",\n",
    "     train = True,\n",
    "     download = True,\n",
    "     transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "     root = \"data\",\n",
    "     train = False,\n",
    "     download = True,\n",
    "     transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       file_name  label\n",
      "0          0.png      9\n",
      "1          1.png      0\n",
      "2          2.png      0\n",
      "3          3.png      3\n",
      "4          4.png      0\n",
      "...          ...    ...\n",
      "59995  59995.png      5\n",
      "59996  59996.png      1\n",
      "59997  59997.png      3\n",
      "59998  59998.png      0\n",
      "59999  59999.png      5\n",
      "\n",
      "[60000 rows x 2 columns]\n",
      "     file_name  label\n",
      "0        0.png      9\n",
      "1        1.png      2\n",
      "2        2.png      1\n",
      "3        3.png      1\n",
      "4        4.png      6\n",
      "...        ...    ...\n",
      "9995  9995.png      9\n",
      "9996  9996.png      1\n",
      "9997  9997.png      8\n",
      "9998  9998.png      1\n",
      "9999  9999.png      5\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3. test_folder 파일 내에 test_images(60,000), train_images(10,000), test_annotations.csv, train_annotations.csv 파일 print\n",
    "# test_images(60,000), train_images(10,000) 양이 많아 임시 삭제 했습니다. 본 파일 실행 시 해당 부분 재 실행 후 파일 다운로드 이후 진행해야 합니다.\n",
    "img_size = 28\n",
    "num_images = 5\n",
    "\n",
    "## save annotation csv\n",
    "# header\n",
    "train_test = [\n",
    "    {\n",
    "        'task_name': 'train',\n",
    "        'image' : 'data/FashionMNIST/raw/train-images-idx3-ubyte',\n",
    "        'label' : 'data/FashionMNIST/raw/train-labels-idx1-ubyte'\n",
    "    },\n",
    "    {\n",
    "        'task_name': 'test',\n",
    "        'image' : 'data/FashionMNIST/raw/t10k-images-idx3-ubyte',\n",
    "        'label' : 'data/FashionMNIST/raw/t10k-labels-idx1-ubyte'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i in train_test : \n",
    "    imgf = open(i['image'],'rb')\n",
    "    imgd = imgf.read(16)\n",
    "    lblf = open(i['label'], 'rb')\n",
    "    lbuf = lblf.read(8)\n",
    "\n",
    "    df_dict = {\n",
    "        'file_name' : [],\n",
    "        'label' : []\n",
    "    }\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        imgd = imgf.read(img_size * img_size)\n",
    "        if not imgd:\n",
    "            break\n",
    "        data = np.frombuffer(imgd, dtype=np.uint8).astype(float)\n",
    "        data = data.reshape(1, img_size, img_size, 1)\n",
    "        image = np.asarray(data).squeeze()\n",
    "        lbld = lblf.read(1)\n",
    "        labels = np.frombuffer(lbld, dtype=np.uint8).astype(np.int64)\n",
    "        file_name = '{}.png'.format(idx)\n",
    "\n",
    "        os.makedirs('./test_folder/FashionMNIST/{}_iamges'.format(i['task_name']), exist_ok = True)\n",
    "\n",
    "        cv2.imwrite('./test_folder/FashionMNIST/{}_iamges/{}'.format(i['task_name'], file_name), image)\n",
    "\n",
    "        idx +=1\n",
    "        df_dict['label'].append(labels[0])\n",
    "        df_dict['file_name'].append(file_name)\n",
    "\n",
    "    # print(df_dict)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    print(df)\n",
    "    df.to_csv('./test_folder/FashionMNIST/{}_annotations.csv'.format(i['task_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1f2b33e866b0bf2409397e5f58ba9cdf170d3b7f64c8f359c79998e2f88ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
